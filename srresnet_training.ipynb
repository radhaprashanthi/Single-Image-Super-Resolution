{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_path = Path(\"..\")\n",
    "\n",
    "assert(root_path.exists())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from srresnet.train import *\n",
    "#612\n",
    "#387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ce4b33ad1b415f9afd6c9864dba82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.089799 (0.091351)\n",
      "1 MSE loss 0.081833 (0.090448)\n",
      "2 MSE loss 0.091590 (0.090272)\n",
      "3 MSE loss 0.091460 (0.089868)\n",
      "4 MSE loss 0.070718 (0.089669)\n",
      "5 MSE loss 0.090204 (0.089442)\n",
      "6 MSE loss 0.074972 (0.089198)\n",
      "7 MSE loss 0.086138 (0.089355)\n",
      "8 MSE loss 0.087284 (0.089203)\n",
      "9 MSE loss 0.072435 (0.089554)\n",
      "10 MSE loss 0.075061 (0.089375)\n",
      "11 MSE loss 0.091500 (0.089402)\n",
      "12 MSE loss 0.075106 (0.089435)\n",
      "13 MSE loss 0.086529 (0.089288)\n",
      "14 MSE loss 0.072812 (0.089313)\n",
      "15 MSE loss 0.081093 (0.089213)\n",
      "16 MSE loss 0.064930 (0.089178)\n",
      "17 MSE loss 0.090254 (0.089154)\n",
      "18 MSE loss 0.087066 (0.089309)\n",
      "19 MSE loss 0.073570 (0.089570)\n",
      "20 MSE loss 0.086193 (0.089836)\n",
      "21 MSE loss 0.085349 (0.089883)\n",
      "22 MSE loss 0.078834 (0.089959)\n",
      "23 MSE loss 0.093439 (0.089809)\n",
      "24 MSE loss 0.090879 (0.089708)\n",
      "25 MSE loss 0.090040 (0.089796)\n",
      "26 MSE loss 0.067911 (0.089795)\n",
      "27 MSE loss 0.062584 (0.089650)\n",
      "28 MSE loss 0.086511 (0.089551)\n",
      "29 MSE loss 0.066915 (0.089496)\n",
      "30 MSE loss 0.084376 (0.089358)\n",
      "31 MSE loss 0.104570 (0.089440)\n",
      "32 MSE loss 0.118909 (0.089404)\n",
      "33 MSE loss 0.111524 (0.089494)\n",
      "34 MSE loss 0.068694 (0.089532)\n",
      "35 MSE loss 0.099728 (0.089515)\n",
      "36 MSE loss 0.099487 (0.089507)\n",
      "37 MSE loss 0.060424 (0.089459)\n",
      "38 MSE loss 0.083747 (0.089485)\n",
      "39 MSE loss 0.095780 (0.089460)\n",
      "40 MSE loss 0.107670 (0.089475)\n",
      "41 MSE loss 0.051825 (0.089429)\n",
      "42 MSE loss 0.124196 (0.089445)\n",
      "43 MSE loss 0.084425 (0.089507)\n",
      "44 MSE loss 0.082489 (0.089407)\n",
      "45 MSE loss 0.074985 (0.089381)\n",
      "46 MSE loss 0.091885 (0.089359)\n",
      "47 MSE loss 0.090352 (0.089404)\n",
      "48 MSE loss 0.089035 (0.089387)\n",
      "49 MSE loss 0.079077 (0.089328)\n",
      "50 MSE loss 0.081944 (0.089366)\n",
      "51 MSE loss 0.094463 (0.089394)\n",
      "52 MSE loss 0.079514 (0.089377)\n",
      "53 MSE loss 0.101689 (0.089305)\n",
      "54 MSE loss 0.071965 (0.089263)\n",
      "55 MSE loss 0.106083 (0.089254)\n",
      "56 MSE loss 0.076161 (0.089230)\n",
      "57 MSE loss 0.068793 (0.089230)\n",
      "58 MSE loss 0.063094 (0.089197)\n",
      "59 MSE loss 0.071954 (0.089192)\n",
      "60 MSE loss 0.065804 (0.089201)\n",
      "61 MSE loss 0.113184 (0.089131)\n",
      "62 MSE loss 0.072955 (0.089072)\n",
      "63 MSE loss 0.054916 (0.089058)\n",
      "64 MSE loss 0.073027 (0.089018)\n",
      "65 MSE loss 0.108351 (0.088988)\n",
      "66 MSE loss 0.103405 (0.088999)\n",
      "67 MSE loss 0.061082 (0.088933)\n",
      "68 MSE loss 0.114466 (0.088905)\n",
      "69 MSE loss 0.087532 (0.088882)\n",
      "70 MSE loss 0.061183 (0.088815)\n",
      "71 MSE loss 0.074836 (0.088845)\n",
      "72 MSE loss 0.094840 (0.088817)\n",
      "73 MSE loss 0.092421 (0.088778)\n",
      "74 MSE loss 0.079024 (0.088769)\n",
      "75 MSE loss 0.082338 (0.088770)\n",
      "76 MSE loss 0.071598 (0.088788)\n",
      "77 MSE loss 0.084958 (0.088748)\n",
      "78 MSE loss 0.092752 (0.088780)\n",
      "79 MSE loss 0.083486 (0.088782)\n",
      "80 MSE loss 0.096031 (0.088707)\n",
      "81 MSE loss 0.095232 (0.088727)\n",
      "82 MSE loss 0.072927 (0.088738)\n",
      "83 MSE loss 0.083165 (0.088763)\n",
      "84 MSE loss 0.073508 (0.088707)\n",
      "85 MSE loss 0.066826 (0.088723)\n",
      "86 MSE loss 0.093169 (0.088758)\n",
      "87 MSE loss 0.102675 (0.088792)\n",
      "88 MSE loss 0.084706 (0.088806)\n",
      "89 MSE loss 0.097447 (0.088769)\n",
      "90 MSE loss 0.091556 (0.088721)\n",
      "91 MSE loss 0.085138 (0.088678)\n",
      "92 MSE loss 0.090815 (0.088699)\n",
      "93 MSE loss 0.072810 (0.088679)\n",
      "94 MSE loss 0.089454 (0.088696)\n",
      "95 MSE loss 0.106093 (0.088693)\n",
      "96 MSE loss 0.070969 (0.088694)\n",
      "97 MSE loss 0.057445 (0.088676)\n",
      "98 MSE loss 0.081774 (0.088617)\n",
      "99 MSE loss 0.112269 (0.088630)\n",
      "100 MSE loss 0.076023 (0.088625)\n",
      "101 MSE loss 0.075753 (0.088612)\n",
      "102 MSE loss 0.070390 (0.088568)\n",
      "103 MSE loss 0.114754 (0.088525)\n",
      "104 MSE loss 0.097080 (0.088562)\n",
      "105 MSE loss 0.093934 (0.088544)\n",
      "106 MSE loss 0.060566 (0.088521)\n",
      "107 MSE loss 0.071230 (0.088510)\n",
      "108 MSE loss 0.069559 (0.088446)\n",
      "109 MSE loss 0.066879 (0.088438)\n",
      "110 MSE loss 0.089648 (0.088412)\n",
      "111 MSE loss 0.079424 (0.088466)\n",
      "112 MSE loss 0.080037 (0.088463)\n",
      "113 MSE loss 0.081832 (0.088398)\n",
      "114 MSE loss 0.075385 (0.088435)\n",
      "115 MSE loss 0.072287 (0.088382)\n",
      "116 MSE loss 0.067131 (0.088341)\n",
      "117 MSE loss 0.073908 (0.088287)\n",
      "118 MSE loss 0.048736 (0.088274)\n",
      "119 MSE loss 0.087920 (0.088250)\n",
      "120 MSE loss 0.061982 (0.088233)\n",
      "121 MSE loss 0.063482 (0.088200)\n",
      "122 MSE loss 0.058366 (0.088165)\n",
      "123 MSE loss 0.078983 (0.088143)\n",
      "124 MSE loss 0.062148 (0.088154)\n",
      "125 MSE loss 0.078226 (0.088116)\n",
      "126 MSE loss 0.081851 (0.088094)\n",
      "127 MSE loss 0.062020 (0.088063)\n",
      "128 MSE loss 0.098428 (0.088015)\n",
      "129 MSE loss 0.081486 (0.087990)\n",
      "130 MSE loss 0.097341 (0.087957)\n",
      "131 MSE loss 0.067164 (0.087936)\n",
      "132 MSE loss 0.090973 (0.087904)\n",
      "133 MSE loss 0.060479 (0.087885)\n",
      "134 MSE loss 0.062296 (0.087878)\n",
      "135 MSE loss 0.063192 (0.087862)\n",
      "136 MSE loss 0.088850 (0.087847)\n",
      "137 MSE loss 0.090854 (0.087855)\n",
      "138 MSE loss 0.072080 (0.087816)\n",
      "139 MSE loss 0.073396 (0.087816)\n",
      "140 MSE loss 0.070759 (0.087798)\n",
      "141 MSE loss 0.057875 (0.087797)\n",
      "142 MSE loss 0.043441 (0.087760)\n",
      "143 MSE loss 0.060460 (0.087701)\n",
      "144 MSE loss 0.066704 (0.087685)\n",
      "145 MSE loss 0.076593 (0.087649)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79d8bf73cac42a4b2eb898f255d1eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.106643 (0.106298)\n",
      "1 MSE loss 0.113943 (0.106718)\n",
      "2 MSE loss 0.074073 (0.104043)\n",
      "3 MSE loss 0.113611 (0.105167)\n",
      "4 MSE loss 0.074231 (0.105024)\n",
      "5 MSE loss 0.112605 (0.105276)\n",
      "6 MSE loss 0.079409 (0.105300)\n",
      "7 MSE loss 0.089657 (0.104515)\n",
      "8 MSE loss 0.116252 (0.104670)\n",
      "9 MSE loss 0.100385 (0.104546)\n",
      "10 MSE loss 0.099125 (0.104299)\n",
      "11 MSE loss 0.118984 (0.104060)\n",
      "12 MSE loss 0.086485 (0.103860)\n",
      "13 MSE loss 0.081786 (0.103658)\n",
      "14 MSE loss 0.107867 (0.103807)\n",
      "15 MSE loss 0.125315 (0.103903)\n",
      "16 MSE loss 0.100561 (0.103910)\n",
      "17 MSE loss 0.105635 (0.103742)\n",
      "18 MSE loss 0.084244 (0.103663)\n",
      "19 MSE loss 0.115845 (0.103603)\n",
      "20 MSE loss 0.068527 (0.103813)\n",
      "21 MSE loss 0.100496 (0.103860)\n",
      "22 MSE loss 0.108237 (0.103730)\n",
      "23 MSE loss 0.089182 (0.103739)\n",
      "24 MSE loss 0.076604 (0.103687)\n",
      "25 MSE loss 0.115721 (0.103647)\n",
      "26 MSE loss 0.079068 (0.103634)\n",
      "27 MSE loss 0.107329 (0.103671)\n",
      "28 MSE loss 0.117034 (0.103613)\n",
      "29 MSE loss 0.076375 (0.103592)\n",
      "30 MSE loss 0.135216 (0.103543)\n",
      "31 MSE loss 0.077994 (0.103483)\n",
      "32 MSE loss 0.086898 (0.103383)\n",
      "33 MSE loss 0.072265 (0.103324)\n",
      "34 MSE loss 0.090098 (0.103210)\n",
      "35 MSE loss 0.102855 (0.103173)\n",
      "36 MSE loss 0.070987 (0.102987)\n",
      "37 MSE loss 0.098833 (0.102948)\n",
      "38 MSE loss 0.095927 (0.102910)\n",
      "39 MSE loss 0.114171 (0.102870)\n",
      "40 MSE loss 0.100300 (0.102750)\n",
      "41 MSE loss 0.102354 (0.102652)\n",
      "42 MSE loss 0.107770 (0.102610)\n",
      "43 MSE loss 0.109478 (0.102580)\n",
      "44 MSE loss 0.087445 (0.102573)\n",
      "45 MSE loss 0.105326 (0.102538)\n",
      "46 MSE loss 0.088530 (0.102543)\n",
      "47 MSE loss 0.104375 (0.102536)\n",
      "48 MSE loss 0.071060 (0.102456)\n",
      "49 MSE loss 0.099577 (0.102439)\n",
      "50 MSE loss 0.121137 (0.102384)\n",
      "51 MSE loss 0.104339 (0.102230)\n",
      "52 MSE loss 0.094970 (0.102228)\n",
      "53 MSE loss 0.098270 (0.102223)\n",
      "54 MSE loss 0.082330 (0.102160)\n",
      "55 MSE loss 0.117115 (0.102010)\n",
      "56 MSE loss 0.079697 (0.101947)\n",
      "57 MSE loss 0.100952 (0.101946)\n",
      "58 MSE loss 0.071593 (0.102020)\n",
      "59 MSE loss 0.087089 (0.101986)\n",
      "60 MSE loss 0.088114 (0.101969)\n",
      "61 MSE loss 0.097699 (0.101951)\n",
      "62 MSE loss 0.081796 (0.101963)\n",
      "63 MSE loss 0.084414 (0.101968)\n",
      "64 MSE loss 0.086337 (0.101934)\n",
      "65 MSE loss 0.091391 (0.101867)\n",
      "66 MSE loss 0.097933 (0.101817)\n",
      "67 MSE loss 0.084700 (0.101770)\n",
      "68 MSE loss 0.091875 (0.101677)\n",
      "69 MSE loss 0.089002 (0.101681)\n",
      "70 MSE loss 0.106996 (0.101634)\n",
      "71 MSE loss 0.087848 (0.101614)\n",
      "72 MSE loss 0.119420 (0.101589)\n",
      "73 MSE loss 0.089059 (0.101573)\n",
      "74 MSE loss 0.105750 (0.101649)\n",
      "75 MSE loss 0.088980 (0.101644)\n",
      "76 MSE loss 0.098184 (0.101661)\n",
      "77 MSE loss 0.079122 (0.101658)\n",
      "78 MSE loss 0.104026 (0.101565)\n",
      "79 MSE loss 0.098054 (0.101533)\n",
      "80 MSE loss 0.070428 (0.101535)\n",
      "81 MSE loss 0.082341 (0.101460)\n",
      "82 MSE loss 0.085063 (0.101376)\n",
      "83 MSE loss 0.091275 (0.101382)\n",
      "84 MSE loss 0.068808 (0.101340)\n",
      "85 MSE loss 0.124033 (0.101291)\n",
      "86 MSE loss 0.110257 (0.101244)\n",
      "87 MSE loss 0.085658 (0.101246)\n",
      "88 MSE loss 0.079277 (0.101274)\n",
      "89 MSE loss 0.082410 (0.101274)\n",
      "90 MSE loss 0.094851 (0.101229)\n",
      "91 MSE loss 0.088751 (0.101172)\n",
      "92 MSE loss 0.069744 (0.101126)\n",
      "93 MSE loss 0.083191 (0.101091)\n",
      "94 MSE loss 0.079806 (0.101036)\n",
      "95 MSE loss 0.083225 (0.101011)\n",
      "96 MSE loss 0.069951 (0.100965)\n",
      "97 MSE loss 0.085191 (0.100894)\n",
      "98 MSE loss 0.072341 (0.100901)\n",
      "99 MSE loss 0.123242 (0.100872)\n",
      "100 MSE loss 0.108406 (0.100860)\n",
      "101 MSE loss 0.085191 (0.100853)\n",
      "102 MSE loss 0.108123 (0.100822)\n",
      "103 MSE loss 0.073110 (0.100811)\n",
      "104 MSE loss 0.100752 (0.100754)\n",
      "105 MSE loss 0.089490 (0.100704)\n",
      "106 MSE loss 0.087605 (0.100690)\n",
      "107 MSE loss 0.089000 (0.100644)\n",
      "108 MSE loss 0.087218 (0.100598)\n",
      "109 MSE loss 0.093313 (0.100558)\n",
      "110 MSE loss 0.079617 (0.100547)\n",
      "111 MSE loss 0.075025 (0.100513)\n",
      "112 MSE loss 0.099459 (0.100478)\n",
      "113 MSE loss 0.116523 (0.100447)\n",
      "114 MSE loss 0.078028 (0.100390)\n",
      "115 MSE loss 0.093109 (0.100344)\n",
      "116 MSE loss 0.079111 (0.100323)\n",
      "117 MSE loss 0.102123 (0.100303)\n",
      "118 MSE loss 0.083488 (0.100231)\n",
      "119 MSE loss 0.094722 (0.100195)\n",
      "120 MSE loss 0.099198 (0.100174)\n",
      "121 MSE loss 0.103510 (0.100105)\n",
      "122 MSE loss 0.082737 (0.100069)\n",
      "123 MSE loss 0.095611 (0.100041)\n",
      "124 MSE loss 0.081803 (0.099980)\n",
      "125 MSE loss 0.100905 (0.099989)\n",
      "126 MSE loss 0.084317 (0.099940)\n",
      "127 MSE loss 0.060637 (0.099871)\n",
      "128 MSE loss 0.075068 (0.099834)\n",
      "129 MSE loss 0.080596 (0.099820)\n",
      "130 MSE loss 0.081703 (0.099778)\n",
      "131 MSE loss 0.064777 (0.099721)\n",
      "132 MSE loss 0.055451 (0.099711)\n",
      "133 MSE loss 0.093163 (0.099706)\n",
      "134 MSE loss 0.084024 (0.099685)\n",
      "135 MSE loss 0.096646 (0.099644)\n",
      "136 MSE loss 0.099999 (0.099624)\n",
      "137 MSE loss 0.099393 (0.099589)\n",
      "138 MSE loss 0.076282 (0.099570)\n",
      "139 MSE loss 0.055736 (0.099536)\n",
      "140 MSE loss 0.121321 (0.099482)\n",
      "141 MSE loss 0.072051 (0.099480)\n",
      "142 MSE loss 0.086629 (0.099445)\n",
      "143 MSE loss 0.086854 (0.099450)\n",
      "144 MSE loss 0.078488 (0.099431)\n",
      "145 MSE loss 0.053415 (0.099380)\n",
      "146 MSE loss 0.087027 (0.099360)\n",
      "147 MSE loss 0.086389 (0.099344)\n",
      "148 MSE loss 0.078960 (0.099303)\n",
      "149 MSE loss 0.093565 (0.099285)\n",
      "150 MSE loss 0.105502 (0.099239)\n",
      "151 MSE loss 0.076681 (0.099200)\n",
      "152 MSE loss 0.092919 (0.099171)\n",
      "153 MSE loss 0.063236 (0.099115)\n",
      "154 MSE loss 0.079418 (0.099053)\n",
      "155 MSE loss 0.106652 (0.099042)\n",
      "156 MSE loss 0.102647 (0.098982)\n",
      "157 MSE loss 0.120774 (0.098950)\n",
      "158 MSE loss 0.083990 (0.098914)\n",
      "159 MSE loss 0.094797 (0.098896)\n",
      "160 MSE loss 0.093849 (0.098863)\n",
      "161 MSE loss 0.109649 (0.098844)\n",
      "162 MSE loss 0.086054 (0.098818)\n",
      "163 MSE loss 0.091812 (0.098777)\n",
      "164 MSE loss 0.088705 (0.098758)\n",
      "165 MSE loss 0.085153 (0.098729)\n",
      "166 MSE loss 0.091966 (0.098730)\n",
      "167 MSE loss 0.091265 (0.098678)\n",
      "168 MSE loss 0.113360 (0.098662)\n",
      "169 MSE loss 0.087389 (0.098638)\n",
      "170 MSE loss 0.073960 (0.098622)\n",
      "171 MSE loss 0.114580 (0.098581)\n",
      "172 MSE loss 0.147346 (0.098578)\n",
      "173 MSE loss 0.082067 (0.098573)\n",
      "174 MSE loss 0.087870 (0.098524)\n",
      "175 MSE loss 0.074446 (0.098495)\n",
      "176 MSE loss 0.099833 (0.098444)\n",
      "177 MSE loss 0.093541 (0.098424)\n",
      "178 MSE loss 0.068909 (0.098395)\n",
      "179 MSE loss 0.110859 (0.098382)\n",
      "180 MSE loss 0.070389 (0.098376)\n",
      "181 MSE loss 0.064917 (0.098364)\n",
      "182 MSE loss 0.099595 (0.098351)\n",
      "183 MSE loss 0.088841 (0.098337)\n",
      "184 MSE loss 0.069037 (0.098299)\n",
      "185 MSE loss 0.066651 (0.098264)\n",
      "186 MSE loss 0.081230 (0.098230)\n",
      "187 MSE loss 0.103037 (0.098227)\n",
      "188 MSE loss 0.078993 (0.098190)\n",
      "189 MSE loss 0.098237 (0.098148)\n",
      "190 MSE loss 0.100400 (0.098146)\n",
      "191 MSE loss 0.098030 (0.098121)\n",
      "192 MSE loss 0.112860 (0.098115)\n",
      "193 MSE loss 0.101826 (0.098105)\n",
      "194 MSE loss 0.110407 (0.098055)\n",
      "195 MSE loss 0.096634 (0.098039)\n",
      "196 MSE loss 0.105401 (0.098009)\n",
      "197 MSE loss 0.070306 (0.097970)\n",
      "198 MSE loss 0.119526 (0.097939)\n",
      "199 MSE loss 0.098308 (0.097933)\n",
      "200 MSE loss 0.077815 (0.097901)\n",
      "201 MSE loss 0.091434 (0.097880)\n",
      "202 MSE loss 0.065471 (0.097837)\n",
      "203 MSE loss 0.078009 (0.097802)\n",
      "204 MSE loss 0.108721 (0.097773)\n",
      "205 MSE loss 0.104981 (0.097766)\n",
      "206 MSE loss 0.090333 (0.097716)\n",
      "207 MSE loss 0.119227 (0.097701)\n",
      "208 MSE loss 0.096020 (0.097660)\n",
      "209 MSE loss 0.100391 (0.097632)\n",
      "210 MSE loss 0.075458 (0.097626)\n",
      "211 MSE loss 0.076134 (0.097617)\n",
      "212 MSE loss 0.098316 (0.097581)\n",
      "213 MSE loss 0.092780 (0.097569)\n",
      "214 MSE loss 0.095822 (0.097551)\n",
      "215 MSE loss 0.100132 (0.097512)\n",
      "216 MSE loss 0.087026 (0.097527)\n",
      "217 MSE loss 0.094591 (0.097523)\n",
      "218 MSE loss 0.101175 (0.097513)\n",
      "219 MSE loss 0.060389 (0.097476)\n",
      "220 MSE loss 0.075396 (0.097436)\n",
      "221 MSE loss 0.081776 (0.097432)\n",
      "222 MSE loss 0.100852 (0.097421)\n",
      "223 MSE loss 0.078904 (0.097412)\n",
      "224 MSE loss 0.089847 (0.097368)\n",
      "225 MSE loss 0.083579 (0.097338)\n",
      "226 MSE loss 0.082452 (0.097299)\n",
      "227 MSE loss 0.068062 (0.097290)\n",
      "228 MSE loss 0.085388 (0.097266)\n",
      "229 MSE loss 0.061351 (0.097219)\n",
      "230 MSE loss 0.079300 (0.097183)\n",
      "231 MSE loss 0.088663 (0.097176)\n",
      "232 MSE loss 0.100133 (0.097152)\n",
      "233 MSE loss 0.068589 (0.097119)\n",
      "234 MSE loss 0.066931 (0.097081)\n",
      "235 MSE loss 0.098819 (0.097048)\n",
      "236 MSE loss 0.074789 (0.097014)\n",
      "237 MSE loss 0.073169 (0.096983)\n",
      "238 MSE loss 0.077988 (0.096956)\n",
      "239 MSE loss 0.075922 (0.096933)\n",
      "240 MSE loss 0.104825 (0.096910)\n",
      "241 MSE loss 0.061623 (0.096876)\n",
      "242 MSE loss 0.111185 (0.096871)\n",
      "243 MSE loss 0.070489 (0.096851)\n",
      "244 MSE loss 0.093019 (0.096822)\n",
      "245 MSE loss 0.068652 (0.096788)\n",
      "246 MSE loss 0.096295 (0.096739)\n",
      "247 MSE loss 0.077140 (0.096711)\n",
      "248 MSE loss 0.096373 (0.096695)\n",
      "249 MSE loss 0.087058 (0.096677)\n",
      "250 MSE loss 0.081970 (0.096655)\n",
      "251 MSE loss 0.094054 (0.096637)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 MSE loss 0.083716 (0.096610)\n",
      "253 MSE loss 0.078405 (0.096574)\n",
      "254 MSE loss 0.085811 (0.096563)\n",
      "255 MSE loss 0.097454 (0.096542)\n",
      "256 MSE loss 0.099524 (0.096526)\n",
      "257 MSE loss 0.110325 (0.096511)\n",
      "258 MSE loss 0.088997 (0.096497)\n",
      "259 MSE loss 0.069893 (0.096476)\n",
      "260 MSE loss 0.083241 (0.096458)\n",
      "261 MSE loss 0.080231 (0.096444)\n",
      "262 MSE loss 0.094007 (0.096410)\n",
      "263 MSE loss 0.077578 (0.096386)\n",
      "264 MSE loss 0.098622 (0.096365)\n",
      "265 MSE loss 0.081704 (0.096337)\n",
      "266 MSE loss 0.095194 (0.096318)\n",
      "267 MSE loss 0.070054 (0.096299)\n",
      "268 MSE loss 0.079418 (0.096270)\n",
      "269 MSE loss 0.069480 (0.096241)\n",
      "270 MSE loss 0.113601 (0.096208)\n",
      "271 MSE loss 0.106222 (0.096188)\n",
      "272 MSE loss 0.100913 (0.096184)\n",
      "273 MSE loss 0.095209 (0.096177)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) #273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04365f29deaf48e5a46a657e7afdc646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.096007 (0.110890)\n",
      "1 MSE loss 0.072067 (0.108965)\n",
      "2 MSE loss 0.146556 (0.108128)\n",
      "3 MSE loss 0.100473 (0.107882)\n",
      "4 MSE loss 0.074850 (0.107494)\n",
      "5 MSE loss 0.095298 (0.107381)\n",
      "6 MSE loss 0.106468 (0.107113)\n",
      "7 MSE loss 0.088696 (0.106921)\n",
      "8 MSE loss 0.099535 (0.106740)\n",
      "9 MSE loss 0.105636 (0.107010)\n",
      "10 MSE loss 0.093375 (0.106748)\n",
      "11 MSE loss 0.086244 (0.107040)\n",
      "12 MSE loss 0.097365 (0.106830)\n",
      "13 MSE loss 0.085333 (0.106546)\n",
      "14 MSE loss 0.133335 (0.106289)\n",
      "15 MSE loss 0.071829 (0.105721)\n",
      "16 MSE loss 0.097044 (0.105745)\n",
      "17 MSE loss 0.085159 (0.105642)\n",
      "18 MSE loss 0.089149 (0.105373)\n",
      "19 MSE loss 0.114895 (0.105685)\n",
      "20 MSE loss 0.105325 (0.105439)\n",
      "21 MSE loss 0.095657 (0.105426)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) #22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286d536edd5b4b898b63018325d54d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.099897 (0.112900)\n",
      "1 MSE loss 0.100994 (0.111993)\n",
      "2 MSE loss 0.102970 (0.109686)\n",
      "3 MSE loss 0.140825 (0.109538)\n",
      "4 MSE loss 0.129591 (0.109756)\n",
      "5 MSE loss 0.084102 (0.109183)\n",
      "6 MSE loss 0.126795 (0.110120)\n",
      "7 MSE loss 0.096781 (0.109807)\n",
      "8 MSE loss 0.081629 (0.109642)\n",
      "9 MSE loss 0.104048 (0.109707)\n",
      "10 MSE loss 0.086066 (0.109476)\n",
      "11 MSE loss 0.098593 (0.109336)\n",
      "12 MSE loss 0.096278 (0.109107)\n",
      "13 MSE loss 0.105085 (0.108954)\n",
      "14 MSE loss 0.125291 (0.108750)\n",
      "15 MSE loss 0.097528 (0.108672)\n",
      "16 MSE loss 0.094768 (0.108490)\n",
      "17 MSE loss 0.103927 (0.108358)\n",
      "18 MSE loss 0.082545 (0.108298)\n",
      "19 MSE loss 0.132447 (0.108224)\n",
      "20 MSE loss 0.086068 (0.108086)\n",
      "21 MSE loss 0.108391 (0.108227)\n",
      "22 MSE loss 0.090835 (0.108252)\n",
      "23 MSE loss 0.105551 (0.108110)\n",
      "24 MSE loss 0.103209 (0.108100)\n",
      "25 MSE loss 0.102756 (0.108134)\n",
      "26 MSE loss 0.107961 (0.108229)\n",
      "27 MSE loss 0.105713 (0.108237)\n",
      "28 MSE loss 0.113743 (0.108273)\n",
      "29 MSE loss 0.125580 (0.108159)\n",
      "30 MSE loss 0.099502 (0.108180)\n",
      "31 MSE loss 0.092203 (0.108053)\n",
      "32 MSE loss 0.104078 (0.108006)\n",
      "33 MSE loss 0.092898 (0.107969)\n",
      "34 MSE loss 0.088372 (0.108038)\n",
      "35 MSE loss 0.097343 (0.107900)\n",
      "36 MSE loss 0.114481 (0.107832)\n",
      "37 MSE loss 0.105845 (0.107782)\n",
      "38 MSE loss 0.088403 (0.107885)\n",
      "39 MSE loss 0.087202 (0.107902)\n",
      "40 MSE loss 0.100945 (0.107848)\n",
      "41 MSE loss 0.105199 (0.107832)\n",
      "42 MSE loss 0.113619 (0.107582)\n",
      "43 MSE loss 0.144591 (0.107403)\n",
      "44 MSE loss 0.121490 (0.107412)\n",
      "45 MSE loss 0.106936 (0.107334)\n",
      "46 MSE loss 0.097984 (0.107221)\n",
      "47 MSE loss 0.091770 (0.107213)\n",
      "48 MSE loss 0.101309 (0.107200)\n",
      "49 MSE loss 0.094138 (0.107201)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ced8440d424dc2973407c366501690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.105325 (0.118253)\n",
      "1 MSE loss 0.111741 (0.116479)\n",
      "2 MSE loss 0.101319 (0.115494)\n",
      "3 MSE loss 0.098992 (0.115162)\n",
      "4 MSE loss 0.133094 (0.115451)\n",
      "5 MSE loss 0.086618 (0.115452)\n",
      "6 MSE loss 0.093234 (0.115139)\n",
      "7 MSE loss 0.096003 (0.115391)\n",
      "8 MSE loss 0.097126 (0.114990)\n",
      "9 MSE loss 0.104535 (0.114809)\n",
      "10 MSE loss 0.093854 (0.114404)\n",
      "11 MSE loss 0.085148 (0.114135)\n",
      "12 MSE loss 0.112327 (0.113666)\n",
      "13 MSE loss 0.092982 (0.113517)\n",
      "14 MSE loss 0.121986 (0.113143)\n",
      "15 MSE loss 0.100075 (0.112891)\n",
      "16 MSE loss 0.121974 (0.112768)\n",
      "17 MSE loss 0.111438 (0.112964)\n",
      "18 MSE loss 0.094985 (0.112963)\n",
      "19 MSE loss 0.077713 (0.112664)\n",
      "20 MSE loss 0.111036 (0.112721)\n",
      "21 MSE loss 0.077857 (0.112585)\n",
      "22 MSE loss 0.107976 (0.112492)\n",
      "23 MSE loss 0.099104 (0.112269)\n",
      "24 MSE loss 0.073264 (0.112159)\n",
      "25 MSE loss 0.082852 (0.111898)\n",
      "26 MSE loss 0.078731 (0.111685)\n",
      "27 MSE loss 0.095744 (0.111725)\n",
      "28 MSE loss 0.074620 (0.111599)\n",
      "29 MSE loss 0.121482 (0.111628)\n",
      "30 MSE loss 0.115720 (0.111638)\n",
      "31 MSE loss 0.090344 (0.111668)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e590ffaea486f91739bde03f4961e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.103758 (0.120509)\n",
      "1 MSE loss 0.122528 (0.115948)\n",
      "2 MSE loss 0.093741 (0.115264)\n",
      "3 MSE loss 0.127610 (0.113888)\n",
      "4 MSE loss 0.108552 (0.113203)\n",
      "5 MSE loss 0.099114 (0.112985)\n",
      "6 MSE loss 0.090917 (0.113060)\n",
      "7 MSE loss 0.087648 (0.112918)\n",
      "8 MSE loss 0.096545 (0.113057)\n",
      "9 MSE loss 0.118602 (0.113430)\n",
      "10 MSE loss 0.105957 (0.113453)\n",
      "11 MSE loss 0.103780 (0.113497)\n",
      "12 MSE loss 0.111821 (0.113345)\n",
      "13 MSE loss 0.082380 (0.113381)\n",
      "14 MSE loss 0.096025 (0.113309)\n",
      "15 MSE loss 0.107472 (0.113315)\n",
      "16 MSE loss 0.096726 (0.113409)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../checkpoints/resnet_checkpoint.pth\n",
      "Resnet: 1549462\n",
      "Length of train loader: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700406e2e2b942948f5c12f8f4654853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE loss 0.187945 (0.202209)\n",
      "1 MSE loss 0.215151 (0.199542)\n",
      "2 MSE loss 0.161203 (0.197765)\n",
      "3 MSE loss 0.185505 (0.196285)\n",
      "4 MSE loss 0.212481 (0.194219)\n",
      "5 MSE loss 0.196179 (0.192481)\n",
      "6 MSE loss 0.199611 (0.190678)\n",
      "7 MSE loss 0.200428 (0.189306)\n",
      "8 MSE loss 0.161477 (0.187820)\n",
      "9 MSE loss 0.179395 (0.186679)\n",
      "10 MSE loss 0.168201 (0.186011)\n",
      "11 MSE loss 0.177966 (0.185526)\n",
      "12 MSE loss 0.171856 (0.184945)\n",
      "13 MSE loss 0.198820 (0.184329)\n",
      "14 MSE loss 0.177302 (0.183883)\n",
      "15 MSE loss 0.210858 (0.183049)\n",
      "16 MSE loss 0.187919 (0.182320)\n",
      "17 MSE loss 0.167979 (0.181660)\n",
      "18 MSE loss 0.205833 (0.181122)\n",
      "19 MSE loss 0.158599 (0.180518)\n",
      "20 MSE loss 0.164044 (0.180051)\n",
      "21 MSE loss 0.142907 (0.179390)\n",
      "22 MSE loss 0.165907 (0.178741)\n",
      "23 MSE loss 0.197914 (0.178121)\n",
      "24 MSE loss 0.144587 (0.177528)\n",
      "25 MSE loss 0.182559 (0.176985)\n",
      "26 MSE loss 0.161905 (0.176521)\n",
      "27 MSE loss 0.178814 (0.176163)\n",
      "28 MSE loss 0.148479 (0.175686)\n",
      "29 MSE loss 0.164143 (0.175157)\n",
      "30 MSE loss 0.147473 (0.174621)\n",
      "31 MSE loss 0.157017 (0.174142)\n",
      "32 MSE loss 0.139121 (0.173683)\n",
      "33 MSE loss 0.190033 (0.173296)\n",
      "34 MSE loss 0.174776 (0.172892)\n",
      "35 MSE loss 0.173452 (0.172363)\n",
      "36 MSE loss 0.178027 (0.172002)\n",
      "37 MSE loss 0.115628 (0.171642)\n",
      "38 MSE loss 0.147660 (0.171165)\n",
      "39 MSE loss 0.141826 (0.170814)\n",
      "40 MSE loss 0.168228 (0.170589)\n",
      "41 MSE loss 0.152743 (0.170173)\n",
      "42 MSE loss 0.141033 (0.169730)\n",
      "43 MSE loss 0.138496 (0.169387)\n",
      "44 MSE loss 0.140046 (0.169123)\n",
      "45 MSE loss 0.144549 (0.168814)\n",
      "46 MSE loss 0.166045 (0.168430)\n",
      "47 MSE loss 0.142451 (0.168121)\n",
      "48 MSE loss 0.150469 (0.167859)\n",
      "49 MSE loss 0.135968 (0.167439)\n",
      "50 MSE loss 0.148668 (0.167139)\n",
      "51 MSE loss 0.145980 (0.166732)\n",
      "52 MSE loss 0.163208 (0.166382)\n",
      "53 MSE loss 0.141030 (0.166103)\n",
      "54 MSE loss 0.134499 (0.165885)\n",
      "55 MSE loss 0.151080 (0.165547)\n",
      "56 MSE loss 0.162802 (0.165309)\n",
      "57 MSE loss 0.162666 (0.165107)\n",
      "58 MSE loss 0.131164 (0.164804)\n",
      "59 MSE loss 0.129249 (0.164619)\n",
      "60 MSE loss 0.124617 (0.164414)\n",
      "61 MSE loss 0.157699 (0.164178)\n",
      "62 MSE loss 0.156216 (0.163888)\n",
      "63 MSE loss 0.134825 (0.163592)\n",
      "64 MSE loss 0.146257 (0.163347)\n",
      "65 MSE loss 0.125822 (0.163079)\n",
      "66 MSE loss 0.152127 (0.162793)\n",
      "67 MSE loss 0.115667 (0.162495)\n",
      "68 MSE loss 0.173158 (0.162303)\n",
      "69 MSE loss 0.146369 (0.162068)\n",
      "70 MSE loss 0.142246 (0.161844)\n",
      "71 MSE loss 0.122859 (0.161579)\n",
      "72 MSE loss 0.117321 (0.161304)\n",
      "73 MSE loss 0.155079 (0.161024)\n",
      "74 MSE loss 0.125503 (0.160739)\n",
      "75 MSE loss 0.150351 (0.160448)\n",
      "76 MSE loss 0.136685 (0.160216)\n",
      "77 MSE loss 0.174009 (0.160058)\n",
      "78 MSE loss 0.155683 (0.159832)\n",
      "79 MSE loss 0.142534 (0.159621)\n",
      "80 MSE loss 0.145840 (0.159367)\n",
      "81 MSE loss 0.163713 (0.159182)\n",
      "82 MSE loss 0.116937 (0.158986)\n",
      "83 MSE loss 0.134897 (0.158783)\n",
      "84 MSE loss 0.143407 (0.158531)\n",
      "85 MSE loss 0.170843 (0.158335)\n",
      "86 MSE loss 0.111193 (0.158089)\n",
      "87 MSE loss 0.157642 (0.157847)\n",
      "88 MSE loss 0.144650 (0.157658)\n",
      "89 MSE loss 0.154880 (0.157469)\n",
      "90 MSE loss 0.139290 (0.157253)\n",
      "91 MSE loss 0.153649 (0.157075)\n",
      "92 MSE loss 0.122776 (0.156902)\n",
      "93 MSE loss 0.101718 (0.156701)\n",
      "94 MSE loss 0.101109 (0.156532)\n",
      "95 MSE loss 0.130553 (0.156348)\n",
      "96 MSE loss 0.118615 (0.156138)\n",
      "97 MSE loss 0.116135 (0.155964)\n",
      "98 MSE loss 0.119600 (0.155743)\n",
      "99 MSE loss 0.100977 (0.155540)\n",
      "100 MSE loss 0.161588 (0.155342)\n",
      "101 MSE loss 0.128590 (0.155111)\n",
      "102 MSE loss 0.144746 (0.154914)\n",
      "103 MSE loss 0.098118 (0.154732)\n",
      "104 MSE loss 0.132218 (0.154550)\n",
      "105 MSE loss 0.118806 (0.154369)\n",
      "106 MSE loss 0.139151 (0.154141)\n",
      "107 MSE loss 0.127232 (0.153949)\n",
      "108 MSE loss 0.109138 (0.153800)\n",
      "109 MSE loss 0.118679 (0.153616)\n",
      "110 MSE loss 0.120282 (0.153405)\n",
      "111 MSE loss 0.128962 (0.153219)\n",
      "112 MSE loss 0.113668 (0.153048)\n",
      "113 MSE loss 0.183689 (0.152937)\n",
      "114 MSE loss 0.136815 (0.152789)\n",
      "115 MSE loss 0.123494 (0.152610)\n",
      "116 MSE loss 0.111761 (0.152448)\n",
      "117 MSE loss 0.110311 (0.152279)\n",
      "118 MSE loss 0.126905 (0.152100)\n",
      "119 MSE loss 0.145203 (0.151910)\n",
      "120 MSE loss 0.126730 (0.151774)\n",
      "121 MSE loss 0.134303 (0.151611)\n",
      "122 MSE loss 0.137604 (0.151495)\n",
      "123 MSE loss 0.122137 (0.151329)\n",
      "124 MSE loss 0.120897 (0.151140)\n",
      "125 MSE loss 0.123203 (0.150988)\n",
      "126 MSE loss 0.104421 (0.150815)\n",
      "127 MSE loss 0.108681 (0.150632)\n",
      "128 MSE loss 0.136021 (0.150471)\n",
      "129 MSE loss 0.134234 (0.150301)\n",
      "130 MSE loss 0.104806 (0.150128)\n",
      "131 MSE loss 0.095802 (0.149936)\n",
      "132 MSE loss 0.114266 (0.149775)\n",
      "133 MSE loss 0.170234 (0.149617)\n",
      "134 MSE loss 0.122518 (0.149443)\n",
      "135 MSE loss 0.127887 (0.149306)\n",
      "136 MSE loss 0.108014 (0.149129)\n",
      "137 MSE loss 0.157279 (0.148987)\n",
      "138 MSE loss 0.138681 (0.148852)\n",
      "139 MSE loss 0.125748 (0.148717)\n",
      "140 MSE loss 0.125440 (0.148577)\n",
      "141 MSE loss 0.137799 (0.148435)\n",
      "142 MSE loss 0.113656 (0.148312)\n",
      "143 MSE loss 0.145252 (0.148155)\n",
      "144 MSE loss 0.118749 (0.148000)\n",
      "145 MSE loss 0.116624 (0.147848)\n",
      "146 MSE loss 0.111623 (0.147718)\n",
      "147 MSE loss 0.124413 (0.147571)\n",
      "148 MSE loss 0.115795 (0.147427)\n",
      "149 MSE loss 0.131295 (0.147294)\n",
      "150 MSE loss 0.116932 (0.147158)\n",
      "151 MSE loss 0.098463 (0.147019)\n",
      "152 MSE loss 0.120684 (0.146894)\n",
      "153 MSE loss 0.120347 (0.146737)\n",
      "154 MSE loss 0.128869 (0.146603)\n",
      "155 MSE loss 0.144139 (0.146473)\n",
      "156 MSE loss 0.153139 (0.146350)\n",
      "157 MSE loss 0.094918 (0.146202)\n",
      "158 MSE loss 0.112954 (0.146073)\n",
      "159 MSE loss 0.127481 (0.145940)\n",
      "160 MSE loss 0.113690 (0.145774)\n",
      "161 MSE loss 0.124696 (0.145620)\n",
      "162 MSE loss 0.123692 (0.145486)\n",
      "163 MSE loss 0.125630 (0.145393)\n",
      "164 MSE loss 0.115545 (0.145255)\n",
      "165 MSE loss 0.095891 (0.145104)\n",
      "166 MSE loss 0.131036 (0.144986)\n",
      "167 MSE loss 0.105639 (0.144831)\n",
      "168 MSE loss 0.131691 (0.144675)\n",
      "169 MSE loss 0.101778 (0.144552)\n",
      "170 MSE loss 0.122920 (0.144415)\n",
      "171 MSE loss 0.120047 (0.144280)\n",
      "172 MSE loss 0.138023 (0.144140)\n",
      "173 MSE loss 0.117263 (0.144004)\n",
      "174 MSE loss 0.134673 (0.143891)\n",
      "175 MSE loss 0.100218 (0.143755)\n",
      "176 MSE loss 0.121632 (0.143641)\n",
      "177 MSE loss 0.092980 (0.143522)\n",
      "178 MSE loss 0.121560 (0.143393)\n",
      "179 MSE loss 0.116251 (0.143251)\n",
      "180 MSE loss 0.137008 (0.143172)\n",
      "181 MSE loss 0.107439 (0.143065)\n",
      "182 MSE loss 0.122375 (0.142947)\n",
      "183 MSE loss 0.127118 (0.142839)\n",
      "184 MSE loss 0.106819 (0.142731)\n",
      "185 MSE loss 0.101274 (0.142602)\n",
      "186 MSE loss 0.119907 (0.142486)\n",
      "187 MSE loss 0.075702 (0.142353)\n",
      "188 MSE loss 0.156146 (0.142221)\n",
      "189 MSE loss 0.145291 (0.142122)\n",
      "190 MSE loss 0.097373 (0.142003)\n",
      "191 MSE loss 0.133059 (0.141890)\n",
      "192 MSE loss 0.113584 (0.141757)\n",
      "193 MSE loss 0.144090 (0.141624)\n",
      "194 MSE loss 0.115185 (0.141504)\n",
      "195 MSE loss 0.096259 (0.141396)\n",
      "196 MSE loss 0.094078 (0.141282)\n",
      "197 MSE loss 0.136143 (0.141154)\n",
      "198 MSE loss 0.108447 (0.141014)\n",
      "199 MSE loss 0.129871 (0.140917)\n",
      "200 MSE loss 0.096861 (0.140803)\n",
      "201 MSE loss 0.123391 (0.140681)\n",
      "202 MSE loss 0.122784 (0.140558)\n",
      "203 MSE loss 0.105863 (0.140454)\n",
      "204 MSE loss 0.092919 (0.140344)\n",
      "205 MSE loss 0.113070 (0.140236)\n",
      "206 MSE loss 0.121527 (0.140111)\n",
      "207 MSE loss 0.130445 (0.140010)\n",
      "208 MSE loss 0.123901 (0.139917)\n"
     ]
    }
   ],
   "source": [
    "train(root_path) #218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
