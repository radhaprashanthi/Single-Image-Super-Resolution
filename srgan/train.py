# -*- coding: utf-8 -*-
"""01_srgan_srresnet_v0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J1lpbAXgiKQgVUdf0E5h-uI8G24xVG1z

SRGAN

https://towardsdatascience.com/build-a-super-simple-gan-in-pytorch-54ba349920e4
"""

from skimage.metrics import peak_signal_noise_ratio, structural_similarity
# from google.colab import drive
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm

from srgan.checkpoint import *
from srgan.dataset import *
from srgan.loss import *
from srgan.models import *
from srgan.utils import AverageMeter

from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter('runs/srgan')


def train_model(generator, optimizer_g,
                discriminator, optimizer_d,
                vgg_loss, device,
                train_dataloader, filepath,
                epochs=100, save_freq=5):
    iterations = epochs * len(train_dataloader)
    progress = tqdm(total=iterations)
    content_loss_criterion = nn.MSELoss()
    adversarial_loss_criterion = nn.BCEWithLogitsLoss()

    beta = 1e-3
    vgg_loss_meter = AverageMeter("VGG loss")
    g_add_loss_meter = AverageMeter("Adversarial loss(G)")
    d_add_loss_meter = AverageMeter("Adversarial loss(D)")

    psnr_meter = AverageMeter("PSNR")
    ssim_meter = AverageMeter("SSIM")

    for epoch in range(epochs):
        generator.train()
        for lr, hr in train_dataloader:
            lr, hr = lr.to(device), hr.to(device)
            batch_size = lr.shape[0]

            ###########################################################################################################
            # Train generator
            sr = generator(lr)
            sr = output_to_imagenet(sr)
            sr_vgg = vgg_loss(sr)
            hr_vgg = vgg_loss(hr).detach()
            fake = discriminator(sr)

            # how close is sr to hr?
            # does vgg19 think sr is similar to hr?
            content_loss = content_loss_criterion(sr_vgg, hr_vgg)

            # make-believe
            # can sr be faked as hr?
            adversarial_loss = adversarial_loss_criterion(fake,
                                                          torch.ones_like(fake))
            # use the above losses
            perceptual_loss = content_loss + (beta * adversarial_loss)

            # Back-prop loss on Generator
            optimizer_g.zero_grad()
            perceptual_loss.backward()

            # Update generator
            optimizer_g.step()

            vgg_loss_meter.update(content_loss.item(), batch_size)
            g_add_loss_meter.update(adversarial_loss.item(), batch_size)

            ###########################################################################################################
            # Train discriminator
            real = discriminator(hr)
            fake = discriminator(sr.detach())

            # can discriminator identify fake and real?
            # x is image and y (is_real) flag
            adversarial_loss = (adversarial_loss_criterion(fake, torch.zeros_like(fake)) +
                                adversarial_loss_criterion(real, torch.ones_like(real)))

            # Back-prop loss on Discriminator
            optimizer_d.zero_grad()
            adversarial_loss.backward()

            # Update discriminator
            optimizer_d.step()

            d_add_loss_meter.update(adversarial_loss.item(), batch_size)

            ###########################################################################################################

            if epoch % 25 == 0:
                hr_y = output_to_y_channel(hr)
                sr_y = output_to_y_channel(sr)
                psnr = (
                    peak_signal_noise_ratio(
                        hr_y.cpu().numpy(),
                        sr_y.cpu().numpy(),
                        data_range=255.)
                )
                ssim = (
                    structural_similarity(
                        hr_y.cpu().numpy(),
                        sr_y.cpu().numpy(),
                        data_range=255.)
                )

                psnr_meter.update(psnr, batch_size)
                ssim_meter.update(ssim, batch_size)

                print("\n**********************\n")
                print(psnr_meter)
                print(ssim_meter)
                print("\n**********************\n")

                del hr_y, sr_y

            del lr, hr, sr
            progress.update()
        print("\n======================\n")
        print(vgg_loss_meter)
        print(g_add_loss_meter)
        print(d_add_loss_meter)
        print("\n======================\n")
        if epoch % save_freq == 0:
            save_checkpoint(generator, discriminator, filepath)

    return generator


def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(device)
    upscale_factor = 4
    image_channels = 3
    residual_block_channels = 64
    num_residual_blocks = 16
    generator = Generator(upscale_factor=upscale_factor,
                          image_channels=image_channels,
                          residual_block_channels=residual_block_channels,
                          num_residual_blocks=num_residual_blocks).to(device)
    num_middle_blocks = 7
    discriminator = Discriminator(
        image_channels=image_channels,
        num_middle_blocks=num_middle_blocks).to(device)
    vgg_loss = VGG19Loss(i=5, j=4).to(device).eval()

    print(f"Generator: {sum(param.numel() for param in generator.parameters())}")
    print(f"Discriminator: {sum(param.numel() for param in discriminator.parameters())}")

    train_dataset = SRImageDataset(
        dataset_dir="/content/drive/My Drive/ML/sr/training_data",
        crop_size=96
    )

    train_dataloader = DataLoader(
        dataset=train_dataset, batch_size=200,
        num_workers=4
    )

    print(f"Length of train loader: {len(train_dataloader)}")

    save_filepath = "/content/drive/My Drive/ML/sr/model_checkpoint/srgan_v0.pth"
    load_filepath = "/content/drive/My Drive/ML/sr/model_checkpoint/srgan_v0.pth"
    lr = 1e-4
    optimizer_g = torch.optim.Adam(params=filter(lambda p: p.requires_grad, generator.parameters()),
                                   lr=lr)
    optimizer_d = torch.optim.Adam(params=filter(lambda p: p.requires_grad, discriminator.parameters()),
                                   lr=lr)

    generator = train_model(generator=generator,
                            optimizer_g=optimizer_g,
                            discriminator=discriminator,
                            optimizer_d=optimizer_d,
                            device=device,
                            vgg_loss=vgg_loss,
                            train_dataloader=train_dataloader,
                            epochs=10, save_freq=5,
                            filepath=save_filepath)

    if __name__ == '__main__':
        train()
